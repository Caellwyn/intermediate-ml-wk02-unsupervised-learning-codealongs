{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642a83d0-19e8-4d43-9513-a19833754c6d",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "In this notebook we will locate anomalous data in a dataset using two different approaches: \n",
    "\n",
    "* KMeans Clustering\n",
    "* Isolation Forests\n",
    "\n",
    "We will visualize anomalous data by reducing the dimensionality using PCA\n",
    "\n",
    "The data we are using is regarding HVAC operation in a building.  It includes sensor data describing temperatures, humidity, and power needed by fans.\n",
    "\n",
    "The dataset was downloaded from Mendeley Data and contributed by Davide Borda.  It can be found [here.](https://data.mendeley.com/datasets/mjhr46dkj6/1)\n",
    "\n",
    "## Data Description\n",
    "\n",
    "1. timestamp;\r\n",
    "2. temperatures of return, supply and outdoor air [°C];\r\n",
    "3. relative humidities of return, supply and outdoor air [%];\r\n",
    "4. the temperature setpoint of the return air [°C];\r\n",
    "5. the saturation temperature in the humidifier [°C];\r\n",
    "6.  power required by the fans [kW];\r\n",
    "7. energy required by the fans [kWh]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ae67a-1928-40da-b2b8-93d75aa0d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import silhouette_score\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf77ec4-08d7-4391-8e8c-647f51ba9ecd",
   "metadata": {},
   "source": [
    "# Load Data and Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a64fd-bfea-4248-8171-5adc5b5ed48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/HVAC_Data.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96346804-478b-4a4e-9bf0-125a5f31a4f7",
   "metadata": {},
   "source": [
    "We could use strategies for timeseries anomaly detection, but in this notebook we are focusing on non-timeseries strategies.  We will drop the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a2308-6d6a-4897-8ea5-c85bd8b69790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73884af1-6e47-4535-a479-003f586529a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove GMT offset and convert to datetime\n",
    "df['Timestamp'] = df['Timestamp'].str.split('+').str[0]\n",
    "\n",
    "format = '%Y-%m-%d %H:%M:%S'\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.set_index('Timestamp')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b8b1f-bfb0-4620-a625-2c1621c3ed23",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f7961-4932-41fc-b98d-0e0f1147428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36f6bf-fb70-4649-8df4-7183c9a5252b",
   "metadata": {},
   "source": [
    "Many of the features are close to normally distributed, but there are some long tails on some of them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c74d56-5808-49e4-b58d-c8f7071061f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7887f-9e75-46f7-816f-0a13c6ec84ba",
   "metadata": {},
   "source": [
    "With the exception of SP_Return there don't seem to be many extreme outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dad50-4058-4c10-ab2c-799517132d58",
   "metadata": {},
   "source": [
    "# KMeans\n",
    "\n",
    "In this section we will use a KMeans model to determine outlier data.\n",
    "\n",
    "Steps:\n",
    "1. Determine k number of clusters\n",
    "2. Identify cluster centers and measure distance between each data point and each cluster center.\n",
    "3. Label points farthest away from any cluster center as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dd19b-9458-40f1-abcb-1cae11e6db97",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "Since this is unsupervised, we do not need to perform a validation split.  However, we do need to scale the data for KMeans models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886c7d4-f247-4af1-ad1d-6c45bc61848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale the data\n",
    "df_scaled = StandardScaler().fit_transform(df)\n",
    "df_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee7673-0d91-4b1e-a545-358a5661944c",
   "metadata": {},
   "source": [
    "# Determine a value for K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f7f82-107e-43a8-8008-78795cd7c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a range of k numbers of clusters\n",
    "ks = range(2,11)\n",
    "\n",
    "## Create lists to hold the inertia and silhouette scores\n",
    "inertias = []\n",
    "sils = []\n",
    "\n",
    "## Loop over k values to determine the best number of clusters for the model\n",
    "for k in ks:\n",
    "    ## create and fit a KMeans model\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42).fit(df_scaled)\n",
    "    \n",
    "    ## Append the inertia and silhouette scores to the lists\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    sils.append(silhouette_score(df_scaled, kmeans.labels_))\n",
    "\n",
    "## Plot the inertias and silhouette scores to determine the right number of clusters\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "axes[0].plot(ks, inertias)\n",
    "axes[0].set_title('Inertia')\n",
    "\n",
    "axes[1].plot(ks, sils)\n",
    "axes[1].set_title('Silhouette Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6849b73a-4b73-4866-a7f9-32a392a6cd4b",
   "metadata": {},
   "source": [
    "## Fit final KMeans\n",
    "\n",
    "Now that we have found the optimal number of clusters, we will fit our final KMeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaacb50-47e9-4b25-a09f-2ceba27f2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = ##How many clusters?\n",
    "kmeans = KMeans(n_clusters=7, random_state=n_clusters).fit(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a9cb5-0d87-40a4-904f-f6ea8477759d",
   "metadata": {},
   "source": [
    "## Determine distance from cluster centers.\n",
    "\n",
    "We will use the `scipy.spatial.distance.cdist` package to find the distances between each scaled datapoint and each cluster center.  This will be an array with one row per data point and one column per cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316ed99-5110-452c-a566-2e418120acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb2f5d-cbc2-47d2-b34d-e02562761708",
   "metadata": {},
   "source": [
    "## Find the distance to the closest cluster for each data point.  \n",
    "\n",
    "How far is each datapoint from it's cluster center?  The data points that are farthest from their closest cluster center will be labeled anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d31bef-3afc-4338-a837-34780294c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum distance to a cluster center for each data point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e83fc3-a336-45a3-87dd-683d193f3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine a histogram of minimum distances\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13813b15-8847-4279-85d6-3bff2d1ba9de",
   "metadata": {},
   "source": [
    "## Determine a Threshold for Anomalies\n",
    "\n",
    "We can see in the plot above that we have some outliers in distances.  The distribution is fairly normal until about 3ish.\n",
    "\n",
    "A more rigorous way than just eyeballing this would be to choose a percentile.  Let's see what a 99.7th percentile, or 3 standard deviations, cutoff would look like.  This means isolating any points that are farther away from the closest cluster center than 95% of other points.  5% of data points would be classified as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea6614-91dd-4c9f-a4ef-6bf4d2969f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine 99.7th percentile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3a34d-d2bb-4167-9664-e891dee3744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a histogram of distances to closest cluster\n",
    "\n",
    "\n",
    "\n",
    "## Add a vertical span at the 95% mark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314ecf2-cfcc-462b-93f3-e5d194cc2f34",
   "metadata": {},
   "source": [
    "## Isolate data points above the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5defe-a58c-4679-8acf-1d1392c6478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a filter for which data points are outside the distance threshold\n",
    "\n",
    "\n",
    "\n",
    "## Filter the original dataset to inspect the anomalous data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db013a-4933-44c2-81e2-1ec73542b15c",
   "metadata": {},
   "source": [
    "We can see that we seem to have stretches of anomalous points.  Our data is in 15 minutes increments and our anamalous seem to come in sequences.  let's see if we can visualize this.\n",
    "\n",
    "Let's compare it to the outdoor temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e199c2-a9dd-4d60-a508-e6d364b1d867",
   "metadata": {},
   "source": [
    "## Visualizing KMeans Anomalies with PCA\n",
    "\n",
    "\n",
    "In order to visualize the clusters and anomalies, we need to flatten the data down to 2 dimensions.  We can use PCA for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb07dc9f-1828-4090-8648-7d4749396da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## instantiate PCA\n",
    "\n",
    "\n",
    "\n",
    "## PCA transform data\n",
    "\n",
    "\n",
    "\n",
    "## filter anomalies\n",
    "\n",
    "\n",
    "\n",
    "## Plot clusters and anomalies\n",
    "plt.scatter(data_to_plot.iloc[:,0], data_to_plot.iloc[:,1], c=kmeans.labels_, label='normal')\n",
    "plt.scatter(kmeans_anomalies.iloc[:,0], kmeans_anomalies.iloc[:,1], c='red', label='anomaly')\n",
    "plt.title('Clusters and Anomalies')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee5b3a-c627-4bb1-8de5-fd5d625ba9f5",
   "metadata": {},
   "source": [
    "Some of the anomalies are at the edges of the main cluster, but others are in the center.  This doesn't much help us visualize them in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793cf5a-b3d0-470e-814a-e90aa6a59ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot as time series\n",
    "\n",
    "\n",
    "\n",
    "## add vertical line at each anomaly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1866d-534f-4772-8c2e-347a124a29e6",
   "metadata": {},
   "source": [
    "We do seem to have some missing data for a few years in the middle monthsbetween May and November 2020j, but we can see some long stretches of time with anomalies in the warmest months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c111839e-1a2f-40e6-82c7-93978594ddc2",
   "metadata": {},
   "source": [
    "# Isolation forests\n",
    "\n",
    "Isolation forests take a different approach.  They create a series of decision trees and determine which datapoints are reachable on the tree via the shortest paths.  Since this is an ensemble model, it will make many trees and average the distances from origin node (root) to terminal node (leaf)\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Instantiate the model.  We need to set a 'contamination' level, or what percentage of the data we think will be anomalies.  Since we used 3 STDs for the KMeans model, we will try the same here.  The inverse of 99.7 is 0.3 percent, or .003.\n",
    "2. Make predictions using the model.  In this case, non-anomalies will be marked as 1 and anomalies will be -1.\n",
    "3. Make a filter using the predictions\n",
    "4. Filter and visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44482c9-cc2a-4ee2-9948-b9167f67d663",
   "metadata": {},
   "source": [
    "## Create and fit the model.\n",
    "\n",
    "We will set a contamination of .003 so we get the same number of anomalies as the KMeans.  Normally we would use either statistical methods or business knowledge to set the contamination rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905c821-2e50-4b64-aa19-fd4882c5728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import IsolationForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "## As a tree-based model, the data does not need to be scaled.  \n",
    "## Set contamination to .003\n",
    "\n",
    "\n",
    "\n",
    "## Make predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f513e80-7eee-4ef5-89bd-731249c3476c",
   "metadata": {},
   "source": [
    "## Create a Filter\n",
    "\n",
    "We will create a filter where the model predicted -1 (anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a3248-b05a-4fcf-b6b9-822de4a4e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c68e9-d834-410f-af60-8f779efc78f2",
   "metadata": {},
   "source": [
    "We can see above that this forest only seemed to flag the first period that the KMeans flagged, but not the 2nd time frame.  let's visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e22cda-6291-4cd4-9ade-8abf0ced203f",
   "metadata": {},
   "source": [
    "## Visualizing IsolationForest Anomalies with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf5a26-8a55-4c97-9c92-200ea0759dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## filter anomalies\n",
    "\n",
    "\n",
    "\n",
    "## Plot data and anomalies\n",
    "plt.scatter(data_to_plot.iloc[:,0], data_to_plot.iloc[:,1], c='green', label='normal')\n",
    "plt.scatter(iso_anomalies_to_plot.iloc[:,0], iso_anomalies_to_plot.iloc[:,1], c='Orange', label='Isolation Forest Anomaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85949a-38f8-4284-9544-1ece0fcf41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot as time series\n",
    "\n",
    "\n",
    "\n",
    "## add vertical line at each anomaly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af9e85-f4da-4fec-8311-53b06fb62955",
   "metadata": {},
   "source": [
    "# Compare KMeans and Isolation Forest\n",
    "\n",
    "We can already see that our models do not agree on all anomalies, let's compare them to get a better sense of the overlap.\n",
    "\n",
    "We will:\n",
    "1. See how many points they agree on\n",
    "2. See which points they agree on\n",
    "3. Compare the statistics on the samples they agree on\n",
    "4. Plot the points to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279721be-c56b-4548-ab28-90b7e0fec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What percent of the data do the models agree are anomalous?\n",
    "\n",
    "## Find where models agree on an anomaly \n",
    "\n",
    "\n",
    "\n",
    "## Count how many they agree on\n",
    "percent_agree = 100 * len(agree_anomaly) / len(df)\n",
    "print(f'Of {len(iso_anomalies)} samples that each model identified as anomalous, they agree on {len(agree_anomaly)}.  This is {percent_agree}% of the total data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983488ee-f8a2-4540-af34-167c183d388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the samples that the models agree on\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812dd31-e047-424a-bb7e-d509f5364c00",
   "metadata": {},
   "source": [
    "These are all on between October 15th and October 18th, 2019.  This may lead us to believe that something strange was happening during this time period with the HVAC system.  This is also within 9 hours of the beginning of the data collected.  It may be that this was shortly after the system was installed.  We can also see that the relative humidity outside (RH_outside) was very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05c101-cb6a-4c5e-94b3-3e66a1d30faa",
   "metadata": {},
   "source": [
    "## Compare statistics for anomalous data vs all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6331de-9066-41c4-8050-6f722388e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe the anomalous data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f53aac-3e3e-45e1-9794-c97a1657ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descibe all of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43021ff6-b293-4c77-86d4-1c53f75ba4e0",
   "metadata": {},
   "source": [
    "We see here that that average humidity, energy, and power are all much higher in the anomalous data both models agree on than in the data overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08ab23-9ee1-444b-b86d-b08bbe8a68fb",
   "metadata": {},
   "source": [
    "## Visualize Agreed Upon Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90534a1-f621-4ee8-8460-bec8256c73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot data and anomalies\n",
    "plt.scatter(data_to_plot.iloc[:,0], data_to_plot.iloc[:,1], c='green', label='normal')\n",
    "plt.scatter(iso_anomalies_to_plot.iloc[:,0], iso_anomalies_to_plot.iloc[:,1], c='red', label='Isolation Forest Anomaly')\n",
    "plt.scatter(kmeans_anomalies.iloc[:,0], kmeans_anomalies.iloc[:,1], c='blue', label='KMeans Anomaly')\n",
    "plt.scatter(agree_anomaly.iloc[:,0], agree_anomaly.iloc[:,1], c='purple', label='Kmeans and Iso Agree')\n",
    "\n",
    "plt.title('Comparing Anomalies')\n",
    "plt.legend(bbox_to_anchor=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e98c3-b269-4051-8f99-3b6debea49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot as time series\n",
    "ax = df['T_Outdoor'].plot()\n",
    "\n",
    "## add vertical line at each anomaly\n",
    "for anom in df[agree_filter].index:\n",
    "    ax.axvline(anom, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83e960-1ac8-4d36-b748-35dbd1324637",
   "metadata": {},
   "source": [
    "In this notebook we looked for anomalous data in measurements taking from an HVAC system using KMeans and Isolation Forest models.  We found that on the rows they agree on they humidity was much higher and the system was using more power and energy.\n",
    "\n",
    "We examined the rows, summary statistics, and visualized the data to build our understanding of the anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6677f-43ac-4e62-a243-7f3be3b71537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
